
_target_: rl.sample_factory.trainer.SampleFactoryTrainer

defaults:
  - trainer

args:
  train_dir: ${data_dir}/sample_factory
  device: ${device}
  decorrelate_experience_max_seconds: 0
  num_workers: ${..num_workers}
  save_every_sec: 30
  experiment: ${run}

  load_checkpoint_kind: latest
  nonlinearity: elu
  normalize_input: False

  seed: ${seed}

  recurrence: 256
  rollout: 256

  aux_loss_coeff: 0
  value_loss_coeff: 0.976
  exploration_loss: symmetric_kl
  exploration_loss_coeff: 0.002

  policy_initialization: orthogonal

  learning_rate: 0.0001
  max_policy_lag: 50
