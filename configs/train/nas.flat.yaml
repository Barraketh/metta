
num_envs_per_worker: ???
num_workers: ???
resume: true

total_timesteps: 50_000_000_000

learning_rate: 0.0017192769489563081
gamma: 0.9572813674006454
gae_lambda: 0.8476682827579273
clip_coef: 0.013625670729361545
vf_coef: 0.8085671540195685
vf_clip_coef: 0.07744138835309457
max_grad_norm: 1.1407346725463867
ent_coef: 0.0038399624938849557


norm_adv: True
clip_vloss: True
target_kl: null
anneal_lr: false

env_batch_size: null
zero_copy: true
verbose: true

checkpoint_interval: 60
wandb_checkpoint_interval: 300

batch_size: 262144
minibatch_size: 16384
bptt_horizon: 32
update_epochs: 3

cpu_offload: false
compile: false
compile_mode: reduce-overhead

forward_pass_minibatch_target_size: 4096
async_factor: 2

stats:
  overview:
    episode/reward.mean: episode_reward
  step: train/agent_steps


