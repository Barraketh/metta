
num_envs_per_worker: ???
num_workers: ???
resume: true

total_timesteps: 5_000_000
batch_size: 32768
minibatch_size: 1024
update_epochs: 2
bptt_horizon: 8
learning_rate: 0.0006112614226003401
gae_lambda: 0.9590507508564148
gamma: 0.9671759718055382
ent_coef: 0.01557519441744131
clip_coef: 0.3031963355045393
vf_clip_coef: 0.13369578727174328
vf_coef: 0.9274225135298954
max_grad_norm: 1.392141580581665

frameskip: 4
repeat_action_probability: 0.0

norm_adv: True
clip_vloss: True
target_kl: null
anneal_lr: false

env_batch_size: null
zero_copy: true
verbose: true

checkpoint_interval: 60
wandb_checkpoint_interval: 300

cpu_offload: false
compile: false
compile_mode: reduce-overhead

forward_pass_minibatch_target_size: 1024
async_factor: 2

stats:
  overview:
    episode/reward.mean: episode_reward
  step: train/agent_steps

