# @package __global__

#POLICIES TO EVALUATE

#b.daphne.navigation_varied_obstacle_shapes_pretrained.r.1
#b.daphne.navigation_varied_obstacle_shapes.r.0
#navigation_poisson_sparser.r.2
#navigation_infinite_cooldown_sparser_pretrained.r.0
#navigation_infinite_cooldown_sparser.r.0
#navigation_poisson_sparser_pretrained.r.6

defaults:
  - _self_

trainer:
  env: /env/mettagrid/object_use/training/multienv_nc
  evaluate_interval: 10


policy_uri: wandb://run/b.georgedeane.george_sequence_no_increment

<<<<<<< HEAD
# policy_uri: wandb://run/b.daphne.terrain_multienv_lessactions:v40
# policy_uri: wandb://run/terrain_multienv_3_single_agent:v63
# policy_uri: wandb://run/terrain_multiagent_24_norewardsharing2
policy_uri: wandb://run/navigation_training
# eval_db_uri: wandb://artifacts/test
# npc_policy_uri: ${trained_policy_uri}

eval_db_uri: wandb://stats/test_nav_scores

# dashboard:
#   # output_path: s3://softmax-public/policydash/dashboard.html
#  # output_path: navigation_results/navigation.html
#   output_path: navigation_results/navigation.html

# sim:
#   env: /env/mettagrid/multiagent/evals/spine_maze_extended



wandb:
  enabled: true
  track: true
  checkpoint_interval: 1

run_id: 105
=======

run_id: 2
>>>>>>> 7e75466bd75398a9206a741a9976b941f66671af
run: ${oc.env:USER}.local.${run_id}
trained_policy_uri: ${run_dir}/checkpoints
