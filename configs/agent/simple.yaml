_target_: agent.metta_agent.MettaAgent

observation_encoder:
  _target_: agent.simple_encoder.SimpleConvAgent
  cnn_channels: 64
  obs_key: grid_obs
  normalize_features: true
  auto_normalize: false
  track_last_action: ${env.track_last_action}
  kinship: ${env.game.kinship}

  fc:
    layers: 1
    output_dim: 128

decoder:
  _target_: agent.decoder.Decoder

core:
  rnn_type: gru
  rnn_num_layers: 1
  rnn_size: 128

policy_selector:
  uri: null
  type: top
  range: 0
  metric: final.score
  generation: null

critic:
  hidden_sizes: [256, 256] # Set to [] for no hidden layer. 
  l2_norm_scales: [1, 2, 3] # don't include nonlinear layers. you can deactivate other layers with 0
  # nonlinearity: Tanh # use the name of the nn function
  # initialization: Xavier
  effective_rank: [False, True, False]

actor:
  hidden_sizes: [256, 256] # Set to [] for no hidden layer
  clip_scales: [1, 2, 3] # don't include nonlinear layers. you can deactivate other layers with 0
  nonlinearity: ReLU # use the name of the nn function
  
clipping_coeff: 3

